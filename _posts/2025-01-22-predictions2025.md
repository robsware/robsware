---
layout: post
title: Predictions for 2025
description: Late night musings on the the next 12 months.
summary: AI, infosec, art, robots and more issues explored through the prism of LLMs.
tags: reflections
---


I haven’t written anything in a while due to various reasons, so I am starting 2025 by making a few lukewarm predictions related to AI, cybersecurity, robots, and some geopolitics.

## AI

LLMs will not lead to ASI or the singularity. Not from where I can see it.

LLMs are an amazing and incredible tool that still have lots of ways to keep growing. They can achieve something very close to AGI in certain fields of knowledge work and will be able to exceed the capability of humans (just like calculators can do better math than people). I reckon it will take more than just 2025, but fields that are relatively narrow in the way they are expressed can and will see significant encroachment by LLMs.

I primarily work in cybersecurity (pentesting and code review/dev), but I am also an avid reader, wannabe artist, tinkerer, and gamer. I have been working with AI on and off since around 2016. My thoughts will focus on those fields primarily.

### Code Generation

Code generation via LLMs will continue to see improvements. There is an immense amount of code to train on thanks to GitHub and other sources, and programmers tend to write code in a similar way. We follow design patterns, avoid anti-patterns, and generally structure for readability and flow. While people still debate whether the advice in *Clean Code* is good or not, the vast majority of programmers follow most of its advice even if certain parts are outdated or superfluous.

Those factors, combined with improvements in logic via Chain of Thought (o1/o3 + other variants), will lead LLMs to become unfathomably good at writing code, with the only speed bump being context size. I think a lot of programmers and engineers ought to focus more on programming language theory (PLT) and design/architecture instead of raw ability to write code.

### Employment Impacts

In regards to employment, I can see it going two ways, depending on the company:

1. **Growth**: Companies will use LLMs to create more — more features, more experiments, more projects. This will not affect employment; it might even boost it. Interviews may shift more towards project-based questions than just leetcode grinding.
2. **Reduction**: Companies (as Meta has announced) will look to trim the fat and reduce the number of developers they have, as existing developers will be able to generate more code. This will affect employment.

At the end of the day, if a company wants to lay you off, they will find a way to do it — with LLMs or without.

### "Perception Space"

LLMs excel in fields with a limited "perception space." Perception space refers to knowledge fields that are deep, objective, and structured. Programming is the best example, but this extends to all computer-related industries.

This is not to say that LLMs will not excel in things such as video generation or image generation. However, once again, they will perform very well if following a standardized format. Tech reviews, makeup tutorials, weather forecasts, and drone shots will all look spectacular, but generating a consistent movie (especially involving physics) will be difficult.

LLMs still struggle with consistency and logic in these areas, and while this can be mitigated to a degree by CoT, reranking, and reasoning models (coupled with throwing a ton of compute at it), it will be far from usable in 2025.

### Open Source Models and Fine-Tuning

In 2025, I expect to see more open-source fine-tuned models, especially those based on reasoning. We’ve seen that o3, when fine-tuned, can beat the ARC-AGI tests at the cost of immense computing power. I expect fine-tuning and smaller models (like DeepSeek) to get more popular.

### Adoption Trends

Adoption and incorporation will continue to grow fairly linearly. Many startups and organizations will need to be built from the ground up around LLMs, but in large enough teams, I can see LLMs already being implemented as helpful assistants with adequate supervision. Hallucinations will continue to be a problem, especially for non-reasoning models, but these will improve in 2025.

### TL;DR

- A lot of linear improvements, with a shift in focus towards smaller-sized models.
- Open source will keep advancing.
- LLMs will reach the performance of an average postgraduate human in a lot of industries.
- Creatives are still largely safe.

---

## Cybersecurity/Infosec

This field is still in the efficiency phase. The number of bug bounties and CVEs keeps going up year by year. LLMs may lead to a great boost in the creation of software, much of which will be buggy — not inherently because LLMs are bad at coding, but because people (especially new or inexperienced programmers) will not direct them adequately.

### Automation

LLMs will see significant usage in infosec, especially multimodal and reasoning models. Bug bounty-level automation can be mixed with capable/fine-tuned models to achieve continuous pentesting across endpoints.

On the blue side, LLMs will help with efficiency, but they will still struggle with parsing the large amounts of data involved in incident response and threat hunting. Nonetheless, they will accelerate learning and mastery of commands tremendously. These predictions only apply for 2025; I expect these issues to be solved in the next few years. The infosec battlefield will turn into a Pokemon-esque situation of throwing the right LLM against the wrong LLM.

### CI/CD Integration

Companies will start experimenting with making LLMs part of their CI/CD pipelines. This will provide increased flexibility and accuracy for every part of the process once fully implemented. However, full implementation will take time due to the complexities involved.

### Social Engineering

Social engineering and phishing attacks will continue (and intensify) as it becomes easier to use LLMs to write convincing emails.

---

## Other Future Tech in 2025

### VR, AR, XR

VR, AR, and XR will become more prevalent. New headsets from Meta and Samsung will show up, with Google trying to get in on the action (and likely failing miserably due to their lack of commitment). I don’t see any mass user adoption happening in 2025. This likely won’t happen until headsets are very light, unobtrusive, and have long battery lives.

The Oculus Quest 3, launched in 2023, was a smash hit and addressed many issues with headsets. However, it is a bit overstretched and underpowered. The software supplied by Meta has also been subpar and often abandoned. Still, it was the first headset where I genuinely saw many of my friends get it, even if they weren’t previously interested in VR.

### Robotics

Robotics will be big and also completely irrelevant in 2025. Many robots will launch this year, but virtually all will be disappointing and little more than novelties.

This is partly because the first iteration of new technology is always imperfect, and partly because creating good general-purpose robots is extremely challenging. LLMs can alleviate issues with planning and object recognition, but actual movement remains incredibly difficult. Hardware advances far slower than software.

---

## Creativity

LLMs remove much of the grunt work required when creating things, especially in programming. Despite this, they plateau in other creative endeavors.

LLMs have an important place in the creative process, particularly for iteration and idea generation, but the final product will require human design and touch. Each of us will become a 10x programmer, artist, director, or writer. I am looking forward to experiencing works created by people who would have never had the time otherwise, though sifting through the general AI slop to find those might be challenging.

---

## Wrap-Up

2025 will be a year of iterations. We will see smaller and smarter models used in more creative ways. Companies and individuals will continue to implement LLMs into products, though adoption will be lopsided as LLMs are overwhelmingly used for work rather than leisure. I am very excited to see affordable and small reasoning models that can be implemented into our daily lives.
